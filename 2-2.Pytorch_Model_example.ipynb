{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import tensor\n",
    "\n",
    "x_data = tensor([[1.0],[2.0],[3.0]])\n",
    "y_data = tensor([[2.0],[4.0],[6.0]])\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model,self).__init__()\n",
    "        self.linear = torch.nn.Linear(1,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y_pred=self.linear(x)\n",
    "        return y_pred\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SGD: stochastic gradient descent = batch (a number of samples)\n",
    "#gradient descent = one sample\n",
    "criterion=torch.nn.MSELoss(reduction=\"sum\")\n",
    "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 12.494275093078613\n",
      "Epoch: 1 | Loss: 5.7046003341674805\n",
      "Epoch: 2 | Loss: 2.679980993270874\n",
      "Epoch: 3 | Loss: 1.3314881324768066\n",
      "Epoch: 4 | Loss: 0.7291883826255798\n",
      "Epoch: 5 | Loss: 0.45910054445266724\n",
      "Epoch: 6 | Loss: 0.3369320333003998\n",
      "Epoch: 7 | Loss: 0.2806411683559418\n",
      "Epoch: 8 | Loss: 0.2537047266960144\n",
      "Epoch: 9 | Loss: 0.23986205458641052\n",
      "Epoch: 10 | Loss: 0.2318761944770813\n",
      "Epoch: 11 | Loss: 0.22652342915534973\n",
      "Epoch: 12 | Loss: 0.22236813604831696\n",
      "Epoch: 13 | Loss: 0.2187718152999878\n",
      "Epoch: 14 | Loss: 0.21544943749904633\n",
      "Epoch: 15 | Loss: 0.21227401494979858\n",
      "Epoch: 16 | Loss: 0.20918777585029602\n",
      "Epoch: 17 | Loss: 0.20616567134857178\n",
      "Epoch: 18 | Loss: 0.20319582521915436\n",
      "Epoch: 19 | Loss: 0.20027250051498413\n",
      "Epoch: 20 | Loss: 0.19739268720149994\n",
      "Epoch: 21 | Loss: 0.1945551484823227\n",
      "Epoch: 22 | Loss: 0.1917591392993927\n",
      "Epoch: 23 | Loss: 0.18900300562381744\n",
      "Epoch: 24 | Loss: 0.1862868070602417\n",
      "Epoch: 25 | Loss: 0.18360942602157593\n",
      "Epoch: 26 | Loss: 0.18097075819969177\n",
      "Epoch: 27 | Loss: 0.17836979031562805\n",
      "Epoch: 28 | Loss: 0.1758061945438385\n",
      "Epoch: 29 | Loss: 0.17327973246574402\n",
      "Epoch: 30 | Loss: 0.17078936100006104\n",
      "Epoch: 31 | Loss: 0.1683349609375\n",
      "Epoch: 32 | Loss: 0.16591572761535645\n",
      "Epoch: 33 | Loss: 0.1635311096906662\n",
      "Epoch: 34 | Loss: 0.1611810028553009\n",
      "Epoch: 35 | Loss: 0.15886451303958893\n",
      "Epoch: 36 | Loss: 0.15658149123191833\n",
      "Epoch: 37 | Loss: 0.15433096885681152\n",
      "Epoch: 38 | Loss: 0.15211302042007446\n",
      "Epoch: 39 | Loss: 0.14992690086364746\n",
      "Epoch: 40 | Loss: 0.14777249097824097\n",
      "Epoch: 41 | Loss: 0.14564862847328186\n",
      "Epoch: 42 | Loss: 0.1435553878545761\n",
      "Epoch: 43 | Loss: 0.14149218797683716\n",
      "Epoch: 44 | Loss: 0.13945873081684113\n",
      "Epoch: 45 | Loss: 0.13745459914207458\n",
      "Epoch: 46 | Loss: 0.13547903299331665\n",
      "Epoch: 47 | Loss: 0.13353191316127777\n",
      "Epoch: 48 | Loss: 0.1316131055355072\n",
      "Epoch: 49 | Loss: 0.1297214925289154\n",
      "Epoch: 50 | Loss: 0.12785720825195312\n",
      "Epoch: 51 | Loss: 0.12601953744888306\n",
      "Epoch: 52 | Loss: 0.12420862913131714\n",
      "Epoch: 53 | Loss: 0.12242364138364792\n",
      "Epoch: 54 | Loss: 0.12066418677568436\n",
      "Epoch: 55 | Loss: 0.11892980337142944\n",
      "Epoch: 56 | Loss: 0.11722072958946228\n",
      "Epoch: 57 | Loss: 0.11553598940372467\n",
      "Epoch: 58 | Loss: 0.11387583613395691\n",
      "Epoch: 59 | Loss: 0.11223908513784409\n",
      "Epoch: 60 | Loss: 0.11062610894441605\n",
      "Epoch: 61 | Loss: 0.10903622955083847\n",
      "Epoch: 62 | Loss: 0.10746929794549942\n",
      "Epoch: 63 | Loss: 0.1059245765209198\n",
      "Epoch: 64 | Loss: 0.10440243035554886\n",
      "Epoch: 65 | Loss: 0.10290202498435974\n",
      "Epoch: 66 | Loss: 0.101422980427742\n",
      "Epoch: 67 | Loss: 0.09996548295021057\n",
      "Epoch: 68 | Loss: 0.09852877259254456\n",
      "Epoch: 69 | Loss: 0.0971127524971962\n",
      "Epoch: 70 | Loss: 0.09571708738803864\n",
      "Epoch: 71 | Loss: 0.09434148669242859\n",
      "Epoch: 72 | Loss: 0.09298567473888397\n",
      "Epoch: 73 | Loss: 0.09164927899837494\n",
      "Epoch: 74 | Loss: 0.09033207595348358\n",
      "Epoch: 75 | Loss: 0.08903388679027557\n",
      "Epoch: 76 | Loss: 0.0877545177936554\n",
      "Epoch: 77 | Loss: 0.08649318665266037\n",
      "Epoch: 78 | Loss: 0.08525034040212631\n",
      "Epoch: 79 | Loss: 0.08402512967586517\n",
      "Epoch: 80 | Loss: 0.0828174576163292\n",
      "Epoch: 81 | Loss: 0.08162727952003479\n",
      "Epoch: 82 | Loss: 0.08045406639575958\n",
      "Epoch: 83 | Loss: 0.07929778844118118\n",
      "Epoch: 84 | Loss: 0.0781581774353981\n",
      "Epoch: 85 | Loss: 0.07703497260808945\n",
      "Epoch: 86 | Loss: 0.07592780143022537\n",
      "Epoch: 87 | Loss: 0.07483677566051483\n",
      "Epoch: 88 | Loss: 0.07376115024089813\n",
      "Epoch: 89 | Loss: 0.07270103693008423\n",
      "Epoch: 90 | Loss: 0.07165618240833282\n",
      "Epoch: 91 | Loss: 0.07062649726867676\n",
      "Epoch: 92 | Loss: 0.06961150467395782\n",
      "Epoch: 93 | Loss: 0.06861097365617752\n",
      "Epoch: 94 | Loss: 0.06762498617172241\n",
      "Epoch: 95 | Loss: 0.06665303558111191\n",
      "Epoch: 96 | Loss: 0.0656951442360878\n",
      "Epoch: 97 | Loss: 0.06475094705820084\n",
      "Epoch: 98 | Loss: 0.0638205036520958\n",
      "Epoch: 99 | Loss: 0.06290321797132492\n",
      "Epoch: 100 | Loss: 0.06199916824698448\n",
      "Epoch: 101 | Loss: 0.061108216643333435\n",
      "Epoch: 102 | Loss: 0.06023000180721283\n",
      "Epoch: 103 | Loss: 0.05936439335346222\n",
      "Epoch: 104 | Loss: 0.05851124972105026\n",
      "Epoch: 105 | Loss: 0.05767034739255905\n",
      "Epoch: 106 | Loss: 0.05684150010347366\n",
      "Epoch: 107 | Loss: 0.056024666875600815\n",
      "Epoch: 108 | Loss: 0.05521943420171738\n",
      "Epoch: 109 | Loss: 0.05442581698298454\n",
      "Epoch: 110 | Loss: 0.05364365503191948\n",
      "Epoch: 111 | Loss: 0.052872687578201294\n",
      "Epoch: 112 | Loss: 0.05211290717124939\n",
      "Epoch: 113 | Loss: 0.05136389285326004\n",
      "Epoch: 114 | Loss: 0.0506257563829422\n",
      "Epoch: 115 | Loss: 0.049898188561201096\n",
      "Epoch: 116 | Loss: 0.04918108507990837\n",
      "Epoch: 117 | Loss: 0.048474185168743134\n",
      "Epoch: 118 | Loss: 0.04777757450938225\n",
      "Epoch: 119 | Loss: 0.04709102585911751\n",
      "Epoch: 120 | Loss: 0.04641406983137131\n",
      "Epoch: 121 | Loss: 0.0457470640540123\n",
      "Epoch: 122 | Loss: 0.04508955031633377\n",
      "Epoch: 123 | Loss: 0.04444161430001259\n",
      "Epoch: 124 | Loss: 0.043802931904792786\n",
      "Epoch: 125 | Loss: 0.04317338019609451\n",
      "Epoch: 126 | Loss: 0.04255295172333717\n",
      "Epoch: 127 | Loss: 0.041941456496715546\n",
      "Epoch: 128 | Loss: 0.04133865237236023\n",
      "Epoch: 129 | Loss: 0.0407446064054966\n",
      "Epoch: 130 | Loss: 0.04015893489122391\n",
      "Epoch: 131 | Loss: 0.0395817905664444\n",
      "Epoch: 132 | Loss: 0.03901299089193344\n",
      "Epoch: 133 | Loss: 0.038452278822660446\n",
      "Epoch: 134 | Loss: 0.03789971396327019\n",
      "Epoch: 135 | Loss: 0.037355002015829086\n",
      "Epoch: 136 | Loss: 0.036818139255046844\n",
      "Epoch: 137 | Loss: 0.03628896176815033\n",
      "Epoch: 138 | Loss: 0.03576740622520447\n",
      "Epoch: 139 | Loss: 0.035253383219242096\n",
      "Epoch: 140 | Loss: 0.03474673256278038\n",
      "Epoch: 141 | Loss: 0.03424745053052902\n",
      "Epoch: 142 | Loss: 0.033755283802747726\n",
      "Epoch: 143 | Loss: 0.03327008709311485\n",
      "Epoch: 144 | Loss: 0.03279201313853264\n",
      "Epoch: 145 | Loss: 0.032320670783519745\n",
      "Epoch: 146 | Loss: 0.031856175512075424\n",
      "Epoch: 147 | Loss: 0.031398337334394455\n",
      "Epoch: 148 | Loss: 0.030947191640734673\n",
      "Epoch: 149 | Loss: 0.030502427369356155\n",
      "Epoch: 150 | Loss: 0.03006402775645256\n",
      "Epoch: 151 | Loss: 0.0296319629997015\n",
      "Epoch: 152 | Loss: 0.02920612506568432\n",
      "Epoch: 153 | Loss: 0.02878631092607975\n",
      "Epoch: 154 | Loss: 0.028372621163725853\n",
      "Epoch: 155 | Loss: 0.02796497754752636\n",
      "Epoch: 156 | Loss: 0.027563033625483513\n",
      "Epoch: 157 | Loss: 0.02716684713959694\n",
      "Epoch: 158 | Loss: 0.026776451617479324\n",
      "Epoch: 159 | Loss: 0.0263916477560997\n",
      "Epoch: 160 | Loss: 0.026012327522039413\n",
      "Epoch: 161 | Loss: 0.025638509541749954\n",
      "Epoch: 162 | Loss: 0.02527005970478058\n",
      "Epoch: 163 | Loss: 0.024906884878873825\n",
      "Epoch: 164 | Loss: 0.024548932909965515\n",
      "Epoch: 165 | Loss: 0.0241960771381855\n",
      "Epoch: 166 | Loss: 0.023848317563533783\n",
      "Epoch: 167 | Loss: 0.023505650460720062\n",
      "Epoch: 168 | Loss: 0.023167826235294342\n",
      "Epoch: 169 | Loss: 0.022834837436676025\n",
      "Epoch: 170 | Loss: 0.022506684064865112\n",
      "Epoch: 171 | Loss: 0.02218325436115265\n",
      "Epoch: 172 | Loss: 0.021864458918571472\n",
      "Epoch: 173 | Loss: 0.0215502567589283\n",
      "Epoch: 174 | Loss: 0.021240506321191788\n",
      "Epoch: 175 | Loss: 0.02093524858355522\n",
      "Epoch: 176 | Loss: 0.020634427666664124\n",
      "Epoch: 177 | Loss: 0.020337741822004318\n",
      "Epoch: 178 | Loss: 0.020045507699251175\n",
      "Epoch: 179 | Loss: 0.019757423549890518\n",
      "Epoch: 180 | Loss: 0.019473494961857796\n",
      "Epoch: 181 | Loss: 0.019193651154637337\n",
      "Epoch: 182 | Loss: 0.018917743116617203\n",
      "Epoch: 183 | Loss: 0.01864592172205448\n",
      "Epoch: 184 | Loss: 0.018377933651208878\n",
      "Epoch: 185 | Loss: 0.018113836646080017\n",
      "Epoch: 186 | Loss: 0.017853498458862305\n",
      "Epoch: 187 | Loss: 0.017596933990716934\n",
      "Epoch: 188 | Loss: 0.017344020307064056\n",
      "Epoch: 189 | Loss: 0.017094751819968224\n",
      "Epoch: 190 | Loss: 0.01684909127652645\n",
      "Epoch: 191 | Loss: 0.016606882214546204\n",
      "Epoch: 192 | Loss: 0.01636832021176815\n",
      "Epoch: 193 | Loss: 0.016132986173033714\n",
      "Epoch: 194 | Loss: 0.01590118743479252\n",
      "Epoch: 195 | Loss: 0.01567266881465912\n",
      "Epoch: 196 | Loss: 0.015447435900568962\n",
      "Epoch: 197 | Loss: 0.015225355513393879\n",
      "Epoch: 198 | Loss: 0.015006606467068195\n",
      "Epoch: 199 | Loss: 0.014790903776884079\n",
      "Epoch: 200 | Loss: 0.014578293077647686\n",
      "Epoch: 201 | Loss: 0.014368852600455284\n",
      "Epoch: 202 | Loss: 0.01416235975921154\n",
      "Epoch: 203 | Loss: 0.013958741910755634\n",
      "Epoch: 204 | Loss: 0.013758194632828236\n",
      "Epoch: 205 | Loss: 0.013560453429818153\n",
      "Epoch: 206 | Loss: 0.013365540653467178\n",
      "Epoch: 207 | Loss: 0.013173507526516914\n",
      "Epoch: 208 | Loss: 0.01298418827354908\n",
      "Epoch: 209 | Loss: 0.012797562405467033\n",
      "Epoch: 210 | Loss: 0.012613599188625813\n",
      "Epoch: 211 | Loss: 0.012432343326508999\n",
      "Epoch: 212 | Loss: 0.012253684923052788\n",
      "Epoch: 213 | Loss: 0.012077560648322105\n",
      "Epoch: 214 | Loss: 0.01190398633480072\n",
      "Epoch: 215 | Loss: 0.011732907965779305\n",
      "Epoch: 216 | Loss: 0.011564275249838829\n",
      "Epoch: 217 | Loss: 0.011398117057979107\n",
      "Epoch: 218 | Loss: 0.011234313249588013\n",
      "Epoch: 219 | Loss: 0.011072828434407711\n",
      "Epoch: 220 | Loss: 0.010913708247244358\n",
      "Epoch: 221 | Loss: 0.01075691543519497\n",
      "Epoch: 222 | Loss: 0.010602304711937904\n",
      "Epoch: 223 | Loss: 0.01044989563524723\n",
      "Epoch: 224 | Loss: 0.01029969286173582\n",
      "Epoch: 225 | Loss: 0.010151720605790615\n",
      "Epoch: 226 | Loss: 0.010005800984799862\n",
      "Epoch: 227 | Loss: 0.009861983358860016\n",
      "Epoch: 228 | Loss: 0.00972023792564869\n",
      "Epoch: 229 | Loss: 0.009580567479133606\n",
      "Epoch: 230 | Loss: 0.009442894719541073\n",
      "Epoch: 231 | Loss: 0.009307177737355232\n",
      "Epoch: 232 | Loss: 0.009173407219350338\n",
      "Epoch: 233 | Loss: 0.009041577577590942\n",
      "Epoch: 234 | Loss: 0.008911652490496635\n",
      "Epoch: 235 | Loss: 0.008783533237874508\n",
      "Epoch: 236 | Loss: 0.008657342754304409\n",
      "Epoch: 237 | Loss: 0.008532924577593803\n",
      "Epoch: 238 | Loss: 0.008410271257162094\n",
      "Epoch: 239 | Loss: 0.008289442397654057\n",
      "Epoch: 240 | Loss: 0.008170302025973797\n",
      "Epoch: 241 | Loss: 0.008052854798734188\n",
      "Epoch: 242 | Loss: 0.007937117479741573\n",
      "Epoch: 243 | Loss: 0.007823023945093155\n",
      "Epoch: 244 | Loss: 0.007710600271821022\n",
      "Epoch: 245 | Loss: 0.0075998310931026936\n",
      "Epoch: 246 | Loss: 0.007490598596632481\n",
      "Epoch: 247 | Loss: 0.007382960990071297\n",
      "Epoch: 248 | Loss: 0.007276831194758415\n",
      "Epoch: 249 | Loss: 0.007172232959419489\n",
      "Epoch: 250 | Loss: 0.007069169543683529\n",
      "Epoch: 251 | Loss: 0.006967575289309025\n",
      "Epoch: 252 | Loss: 0.006867443677037954\n",
      "Epoch: 253 | Loss: 0.006768739782273769\n",
      "Epoch: 254 | Loss: 0.006671477109193802\n",
      "Epoch: 255 | Loss: 0.006575569044798613\n",
      "Epoch: 256 | Loss: 0.006481095217168331\n",
      "Epoch: 257 | Loss: 0.006387931760400534\n",
      "Epoch: 258 | Loss: 0.006296129897236824\n",
      "Epoch: 259 | Loss: 0.006205621175467968\n",
      "Epoch: 260 | Loss: 0.006116499193012714\n",
      "Epoch: 261 | Loss: 0.006028577219694853\n",
      "Epoch: 262 | Loss: 0.0059419190511107445\n",
      "Epoch: 263 | Loss: 0.00585654703900218\n",
      "Epoch: 264 | Loss: 0.005772362928837538\n",
      "Epoch: 265 | Loss: 0.0056894016452133656\n",
      "Epoch: 266 | Loss: 0.00560764642432332\n",
      "Epoch: 267 | Loss: 0.0055270446464419365\n",
      "Epoch: 268 | Loss: 0.005447610281407833\n",
      "Epoch: 269 | Loss: 0.005369329825043678\n",
      "Epoch: 270 | Loss: 0.0052921362221241\n",
      "Epoch: 271 | Loss: 0.005216115154325962\n",
      "Epoch: 272 | Loss: 0.005141168832778931\n",
      "Epoch: 273 | Loss: 0.005067253485321999\n",
      "Epoch: 274 | Loss: 0.00499443244189024\n",
      "Epoch: 275 | Loss: 0.004922652151435614\n",
      "Epoch: 276 | Loss: 0.004851914010941982\n",
      "Epoch: 277 | Loss: 0.0047821542248129845\n",
      "Epoch: 278 | Loss: 0.004713442176580429\n",
      "Epoch: 279 | Loss: 0.004645707085728645\n",
      "Epoch: 280 | Loss: 0.0045789266005158424\n",
      "Epoch: 281 | Loss: 0.00451313704252243\n",
      "Epoch: 282 | Loss: 0.004448277875781059\n",
      "Epoch: 283 | Loss: 0.00438437657430768\n",
      "Epoch: 284 | Loss: 0.004321343265473843\n",
      "Epoch: 285 | Loss: 0.004259247332811356\n",
      "Epoch: 286 | Loss: 0.0041980198584496975\n",
      "Epoch: 287 | Loss: 0.004137676674872637\n",
      "Epoch: 288 | Loss: 0.004078253172338009\n",
      "Epoch: 289 | Loss: 0.004019583575427532\n",
      "Epoch: 290 | Loss: 0.003961858805269003\n",
      "Epoch: 291 | Loss: 0.0039049081970006227\n",
      "Epoch: 292 | Loss: 0.003848802298307419\n",
      "Epoch: 293 | Loss: 0.003793471259996295\n",
      "Epoch: 294 | Loss: 0.0037389672361314297\n",
      "Epoch: 295 | Loss: 0.0036852320190519094\n",
      "Epoch: 296 | Loss: 0.0036322749219834805\n",
      "Epoch: 297 | Loss: 0.0035800659097731113\n",
      "Epoch: 298 | Loss: 0.0035286182537674904\n",
      "Epoch: 299 | Loss: 0.0034778998233377934\n",
      "Epoch: 300 | Loss: 0.0034279129467904568\n",
      "Epoch: 301 | Loss: 0.003378666006028652\n",
      "Epoch: 302 | Loss: 0.0033300642389804125\n",
      "Epoch: 303 | Loss: 0.003282204270362854\n",
      "Epoch: 304 | Loss: 0.003235054202377796\n",
      "Epoch: 305 | Loss: 0.0031885607168078423\n",
      "Epoch: 306 | Loss: 0.003142726607620716\n",
      "Epoch: 307 | Loss: 0.0030975802801549435\n",
      "Epoch: 308 | Loss: 0.003053052583709359\n",
      "Epoch: 309 | Loss: 0.0030091824010014534\n",
      "Epoch: 310 | Loss: 0.0029659115243703127\n",
      "Epoch: 311 | Loss: 0.0029233216773718596\n",
      "Epoch: 312 | Loss: 0.0028812866657972336\n",
      "Epoch: 313 | Loss: 0.0028398996219038963\n",
      "Epoch: 314 | Loss: 0.0027990832459181547\n",
      "Epoch: 315 | Loss: 0.0027588428929448128\n",
      "Epoch: 316 | Loss: 0.0027192123234272003\n",
      "Epoch: 317 | Loss: 0.0026801060885190964\n",
      "Epoch: 318 | Loss: 0.0026416059117764235\n",
      "Epoch: 319 | Loss: 0.0026036188937723637\n",
      "Epoch: 320 | Loss: 0.0025662221014499664\n",
      "Epoch: 321 | Loss: 0.0025293296203017235\n",
      "Epoch: 322 | Loss: 0.002492994535714388\n",
      "Epoch: 323 | Loss: 0.002457156078889966\n",
      "Epoch: 324 | Loss: 0.002421834273263812\n",
      "Epoch: 325 | Loss: 0.0023870381992310286\n",
      "Epoch: 326 | Loss: 0.0023527336306869984\n",
      "Epoch: 327 | Loss: 0.0023189405910670757\n",
      "Epoch: 328 | Loss: 0.0022855866700410843\n",
      "Epoch: 329 | Loss: 0.002252736361697316\n",
      "Epoch: 330 | Loss: 0.002220356836915016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 331 | Loss: 0.0021884702146053314\n",
      "Epoch: 332 | Loss: 0.002156992210075259\n",
      "Epoch: 333 | Loss: 0.0021260129287838936\n",
      "Epoch: 334 | Loss: 0.00209547090344131\n",
      "Epoch: 335 | Loss: 0.002065345412120223\n",
      "Epoch: 336 | Loss: 0.0020356555469334126\n",
      "Epoch: 337 | Loss: 0.0020064152777194977\n",
      "Epoch: 338 | Loss: 0.001977580366656184\n",
      "Epoch: 339 | Loss: 0.0019491645507514477\n",
      "Epoch: 340 | Loss: 0.0019211380276829004\n",
      "Epoch: 341 | Loss: 0.001893531996756792\n",
      "Epoch: 342 | Loss: 0.001866306527517736\n",
      "Epoch: 343 | Loss: 0.0018394727958366275\n",
      "Epoch: 344 | Loss: 0.0018130686366930604\n",
      "Epoch: 345 | Loss: 0.0017870027804747224\n",
      "Epoch: 346 | Loss: 0.001761308521963656\n",
      "Epoch: 347 | Loss: 0.0017360136844217777\n",
      "Epoch: 348 | Loss: 0.0017110484186559916\n",
      "Epoch: 349 | Loss: 0.0016864598728716373\n",
      "Epoch: 350 | Loss: 0.0016622318653389812\n",
      "Epoch: 351 | Loss: 0.0016383507754653692\n",
      "Epoch: 352 | Loss: 0.0016147991409525275\n",
      "Epoch: 353 | Loss: 0.0015915873227640986\n",
      "Epoch: 354 | Loss: 0.0015687000704929233\n",
      "Epoch: 355 | Loss: 0.0015461570583283901\n",
      "Epoch: 356 | Loss: 0.0015239586355164647\n",
      "Epoch: 357 | Loss: 0.0015020561404526234\n",
      "Epoch: 358 | Loss: 0.0014804573729634285\n",
      "Epoch: 359 | Loss: 0.0014591726940125227\n",
      "Epoch: 360 | Loss: 0.001438196748495102\n",
      "Epoch: 361 | Loss: 0.0014175322139635682\n",
      "Epoch: 362 | Loss: 0.00139716942794621\n",
      "Epoch: 363 | Loss: 0.0013770856894552708\n",
      "Epoch: 364 | Loss: 0.0013572971802204847\n",
      "Epoch: 365 | Loss: 0.0013377901632338762\n",
      "Epoch: 366 | Loss: 0.0013185677817091346\n",
      "Epoch: 367 | Loss: 0.001299606286920607\n",
      "Epoch: 368 | Loss: 0.0012809402542188764\n",
      "Epoch: 369 | Loss: 0.0012625351082533598\n",
      "Epoch: 370 | Loss: 0.0012443842133507133\n",
      "Epoch: 371 | Loss: 0.0012264992110431194\n",
      "Epoch: 372 | Loss: 0.0012088669463992119\n",
      "Epoch: 373 | Loss: 0.0011914927745237947\n",
      "Epoch: 374 | Loss: 0.0011743658687919378\n",
      "Epoch: 375 | Loss: 0.0011574976379051805\n",
      "Epoch: 376 | Loss: 0.0011408692225813866\n",
      "Epoch: 377 | Loss: 0.001124476082623005\n",
      "Epoch: 378 | Loss: 0.0011083214776590466\n",
      "Epoch: 379 | Loss: 0.0010923818917945027\n",
      "Epoch: 380 | Loss: 0.0010766817722469568\n",
      "Epoch: 381 | Loss: 0.0010612127371132374\n",
      "Epoch: 382 | Loss: 0.00104595348238945\n",
      "Epoch: 383 | Loss: 0.0010309185599908233\n",
      "Epoch: 384 | Loss: 0.0010161239188164473\n",
      "Epoch: 385 | Loss: 0.0010015118168666959\n",
      "Epoch: 386 | Loss: 0.0009871096117421985\n",
      "Epoch: 387 | Loss: 0.0009729224257171154\n",
      "Epoch: 388 | Loss: 0.0009589494438841939\n",
      "Epoch: 389 | Loss: 0.0009451669175177813\n",
      "Epoch: 390 | Loss: 0.0009315641364082694\n",
      "Epoch: 391 | Loss: 0.0009181902278214693\n",
      "Epoch: 392 | Loss: 0.0009049935615621507\n",
      "Epoch: 393 | Loss: 0.0008919826941564679\n",
      "Epoch: 394 | Loss: 0.0008791693835519254\n",
      "Epoch: 395 | Loss: 0.0008665258646942675\n",
      "Epoch: 396 | Loss: 0.0008540725102648139\n",
      "Epoch: 397 | Loss: 0.0008418121142312884\n",
      "Epoch: 398 | Loss: 0.00082970573566854\n",
      "Epoch: 399 | Loss: 0.0008177951094694436\n",
      "Epoch: 400 | Loss: 0.0008060349500738084\n",
      "Epoch: 401 | Loss: 0.0007944468525238335\n",
      "Epoch: 402 | Loss: 0.0007830207468941808\n",
      "Epoch: 403 | Loss: 0.0007717694388702512\n",
      "Epoch: 404 | Loss: 0.0007606926374137402\n",
      "Epoch: 405 | Loss: 0.0007497404585592449\n",
      "Epoch: 406 | Loss: 0.0007389640668407083\n",
      "Epoch: 407 | Loss: 0.0007283504819497466\n",
      "Epoch: 408 | Loss: 0.0007178962114267051\n",
      "Epoch: 409 | Loss: 0.000707580940797925\n",
      "Epoch: 410 | Loss: 0.0006974032148718834\n",
      "Epoch: 411 | Loss: 0.000687373976688832\n",
      "Epoch: 412 | Loss: 0.0006774900248274207\n",
      "Epoch: 413 | Loss: 0.0006677542114630342\n",
      "Epoch: 414 | Loss: 0.0006581650231964886\n",
      "Epoch: 415 | Loss: 0.0006487102946266532\n",
      "Epoch: 416 | Loss: 0.0006393842631950974\n",
      "Epoch: 417 | Loss: 0.0006302002002485096\n",
      "Epoch: 418 | Loss: 0.0006211347063072026\n",
      "Epoch: 419 | Loss: 0.0006122111808508635\n",
      "Epoch: 420 | Loss: 0.0006034079124219716\n",
      "Epoch: 421 | Loss: 0.0005947378231212497\n",
      "Epoch: 422 | Loss: 0.0005861868849024177\n",
      "Epoch: 423 | Loss: 0.0005777705227956176\n",
      "Epoch: 424 | Loss: 0.0005694648716598749\n",
      "Epoch: 425 | Loss: 0.0005612841923721135\n",
      "Epoch: 426 | Loss: 0.0005532201030291617\n",
      "Epoch: 427 | Loss: 0.0005452578188851476\n",
      "Epoch: 428 | Loss: 0.0005374220199882984\n",
      "Epoch: 429 | Loss: 0.0005297044408507645\n",
      "Epoch: 430 | Loss: 0.0005220852326601744\n",
      "Epoch: 431 | Loss: 0.0005145844770595431\n",
      "Epoch: 432 | Loss: 0.0005071891355328262\n",
      "Epoch: 433 | Loss: 0.0004998967051506042\n",
      "Epoch: 434 | Loss: 0.0004927241243422031\n",
      "Epoch: 435 | Loss: 0.00048563419841229916\n",
      "Epoch: 436 | Loss: 0.0004786566714756191\n",
      "Epoch: 437 | Loss: 0.0004717827250715345\n",
      "Epoch: 438 | Loss: 0.000465003598947078\n",
      "Epoch: 439 | Loss: 0.0004583084082696587\n",
      "Epoch: 440 | Loss: 0.00045172969112172723\n",
      "Epoch: 441 | Loss: 0.0004452329012565315\n",
      "Epoch: 442 | Loss: 0.00043883678154088557\n",
      "Epoch: 443 | Loss: 0.00043254258343949914\n",
      "Epoch: 444 | Loss: 0.0004263130249455571\n",
      "Epoch: 445 | Loss: 0.00042018824024125934\n",
      "Epoch: 446 | Loss: 0.00041415629675611854\n",
      "Epoch: 447 | Loss: 0.0004081891383975744\n",
      "Epoch: 448 | Loss: 0.00040232937317341566\n",
      "Epoch: 449 | Loss: 0.00039654673309996724\n",
      "Epoch: 450 | Loss: 0.0003908461658284068\n",
      "Epoch: 451 | Loss: 0.00038523139664903283\n",
      "Epoch: 452 | Loss: 0.0003797014360316098\n",
      "Epoch: 453 | Loss: 0.00037424295442178845\n",
      "Epoch: 454 | Loss: 0.00036886753514409065\n",
      "Epoch: 455 | Loss: 0.0003635598113760352\n",
      "Epoch: 456 | Loss: 0.0003583368379622698\n",
      "Epoch: 457 | Loss: 0.0003531887778081\n",
      "Epoch: 458 | Loss: 0.00034810396027751267\n",
      "Epoch: 459 | Loss: 0.0003431142249610275\n",
      "Epoch: 460 | Loss: 0.0003381807473488152\n",
      "Epoch: 461 | Loss: 0.00033331598388031125\n",
      "Epoch: 462 | Loss: 0.00032852753065526485\n",
      "Epoch: 463 | Loss: 0.0003238019999116659\n",
      "Epoch: 464 | Loss: 0.0003191584546584636\n",
      "Epoch: 465 | Loss: 0.00031456496799364686\n",
      "Epoch: 466 | Loss: 0.0003100354806520045\n",
      "Epoch: 467 | Loss: 0.0003055835550185293\n",
      "Epoch: 468 | Loss: 0.0003011921071447432\n",
      "Epoch: 469 | Loss: 0.00029686448397114873\n",
      "Epoch: 470 | Loss: 0.000292604963760823\n",
      "Epoch: 471 | Loss: 0.0002883920387830585\n",
      "Epoch: 472 | Loss: 0.00028425376513041556\n",
      "Epoch: 473 | Loss: 0.00028016488067805767\n",
      "Epoch: 474 | Loss: 0.0002761442447081208\n",
      "Epoch: 475 | Loss: 0.0002721728233154863\n",
      "Epoch: 476 | Loss: 0.00026825780514627695\n",
      "Epoch: 477 | Loss: 0.0002643994812387973\n",
      "Epoch: 478 | Loss: 0.0002606076013762504\n",
      "Epoch: 479 | Loss: 0.00025686080334708095\n",
      "Epoch: 480 | Loss: 0.0002531679638195783\n",
      "Epoch: 481 | Loss: 0.00024952669627964497\n",
      "Epoch: 482 | Loss: 0.00024594279238954186\n",
      "Epoch: 483 | Loss: 0.0002424037957098335\n",
      "Epoch: 484 | Loss: 0.00023891923774499446\n",
      "Epoch: 485 | Loss: 0.00023548844910692424\n",
      "Epoch: 486 | Loss: 0.00023211257939692587\n",
      "Epoch: 487 | Loss: 0.00022876900038681924\n",
      "Epoch: 488 | Loss: 0.0002254793798783794\n",
      "Epoch: 489 | Loss: 0.0002222438924945891\n",
      "Epoch: 490 | Loss: 0.00021905590256210417\n",
      "Epoch: 491 | Loss: 0.00021590290998574346\n",
      "Epoch: 492 | Loss: 0.0002127982152160257\n",
      "Epoch: 493 | Loss: 0.00020974210929125547\n",
      "Epoch: 494 | Loss: 0.00020672482787631452\n",
      "Epoch: 495 | Loss: 0.00020375513122417033\n",
      "Epoch: 496 | Loss: 0.00020082751871086657\n",
      "Epoch: 497 | Loss: 0.00019793827959802002\n",
      "Epoch: 498 | Loss: 0.00019510001584421843\n",
      "Epoch: 499 | Loss: 0.0001922991796163842\n"
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "for epoch in range(500):\n",
    "    # 1)forward pass\n",
    "    y_pred=model(x_data)\n",
    "    \n",
    "    # 2)compute loss\n",
    "    loss = criterion(y_pred, y_data)\n",
    "    \n",
    "    print(f\"Epoch: {epoch} | Loss: {loss.item()}\")\n",
    "          \n",
    "    # 3) perform backward pass and update the weights\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step() #update the weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction (after training) 4 7.984059810638428\n"
     ]
    }
   ],
   "source": [
    "# after training\n",
    "hour_var = tensor([[4.0]])\n",
    "y_pred=model(hour_var)\n",
    "print(\"Prediction (after training)\", 4, model(hour_var).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import argparse,os,time\n",
    "import os\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "num_gpus=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## nn.CrossEntropyLoss VS nn.NLLLoss\n",
    "\n",
    "nn.CrossEntropyLoss는 nn.LogSoftmax와 nn.NLLLoss의 연산의 조합이다. nn.LogSoftmax는 신경망 말단의 결과 값들을 확률개념으로 해석하기 위한 Softmax 함수의 결과에 log 값을 취한 연산이고, nn.NLLLoss는 nn.LogSoftmax의 log 결과값에 대한 교차 엔트로피 손실 연산(Cross Entropy Loss|Error)이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"./Otto_Group_Product_data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61873</th>\n",
       "      <td>61874</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61874</th>\n",
       "      <td>61875</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61875</th>\n",
       "      <td>61876</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61876</th>\n",
       "      <td>61877</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61877</th>\n",
       "      <td>61878</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>61878 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0          1       1       0       0       0       0       0       0       0   \n",
       "1          2       0       0       0       0       0       0       0       1   \n",
       "2          3       0       0       0       0       0       0       0       1   \n",
       "3          4       1       0       0       1       6       1       5       0   \n",
       "4          5       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "61873  61874       1       0       0       1       1       0       0       0   \n",
       "61874  61875       4       0       0       0       0       0       0       0   \n",
       "61875  61876       0       0       0       0       0       0       0       3   \n",
       "61876  61877       1       0       0       0       0       0       0       0   \n",
       "61877  61878       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       feat_9  ...  feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "0           0  ...        1        0        0        0        0        0   \n",
       "1           0  ...        0        0        0        0        0        0   \n",
       "2           0  ...        0        0        0        0        0        0   \n",
       "3           0  ...        0        1        2        0        0        0   \n",
       "4           0  ...        1        0        0        0        0        1   \n",
       "...       ...  ...      ...      ...      ...      ...      ...      ...   \n",
       "61873       0  ...        1        0        0        0        0        0   \n",
       "61874       0  ...        0        2        0        0        2        0   \n",
       "61875       1  ...        0        3        1        0        0        0   \n",
       "61876       0  ...        0        0        0        0        1        0   \n",
       "61877       0  ...        0        0        0        0        0        0   \n",
       "\n",
       "       feat_91  feat_92  feat_93   target  \n",
       "0            0        0        0  Class_1  \n",
       "1            0        0        0  Class_1  \n",
       "2            0        0        0  Class_1  \n",
       "3            0        0        0  Class_1  \n",
       "4            0        0        0  Class_1  \n",
       "...        ...      ...      ...      ...  \n",
       "61873        0        2        0  Class_9  \n",
       "61874        0        1        0  Class_9  \n",
       "61875        0        0        0  Class_9  \n",
       "61876        3       10        0  Class_9  \n",
       "61877        0        2        0  Class_9  \n",
       "\n",
       "[61878 rows x 95 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    data=data.replace(\"Class_{}\".format(i),i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_data=data.loc[:,\"feat_1\":].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ...,  1,  0,  5],\n",
       "       [ 0,  0, 23, ...,  0,  0,  6],\n",
       "       [ 0,  0, 11, ...,  0,  0,  6],\n",
       "       ...,\n",
       "       [ 0,  0,  1, ...,  1,  1,  6],\n",
       "       [ 0,  0,  0, ...,  1,  0,  5],\n",
       "       [ 0,  0,  0, ...,  0,  0,  3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.take(shuffle_data,np.random.permutation(shuffle_data.shape[0]),\n",
    "        axis=0,out=shuffle_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=shuffle_data[:,:-1]\n",
    "y_data=shuffle_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x=np.mean(x_data, axis=0)\n",
    "std_x=np.std(x_data, axis=0)\n",
    "x_train=(x_data - mean_x) / std_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,x_dat,y_dat):\n",
    "        x = x_dat\n",
    "        y = y_dat\n",
    "        self.len = x.shape[0]\n",
    "        y=y.astype('int')\n",
    "        x=x.astype('float32')\n",
    "        self.x_data = torch.tensor(x)\n",
    "        self.y_data = torch.tensor(y)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_x, val_data_x, train_data_label, val_data_label = train_test_split(x_data, y_data, \n",
    "                                                                        test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(93, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 1000),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1000, 9),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x=x.view(batch_size//num_gpus,-1)\n",
    "        out=self.fc(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "train_dataset = CustomDataset(train_data_x,train_data_label)\n",
    "train_loader = DataLoader(dataset=train_dataset,pin_memory=True,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=60,drop_last=True)\n",
    "val_dataset = CustomDataset(val_data_x,val_data_label)\n",
    "val_loader = DataLoader(dataset=val_dataset,pin_memory=True,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=60,drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=nn.DataParallel(Model().cuda())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),weight_decay=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/09/28 12:05:22\n",
      "epoch: 1/100 | trn loss: 1.3650 | val loss: 1.0495 | val accuracy: 66.0156% \n",
      "\n",
      "2020/09/28 12:05:35\n",
      "epoch: 2/100 | trn loss: 4.3664 | val loss: 1.0405 | val accuracy: 62.9720% \n",
      "\n",
      "2020/09/28 12:05:48\n",
      "epoch: 3/100 | trn loss: 0.9778 | val loss: 0.9105 | val accuracy: 68.7012% \n",
      "\n",
      "2020/09/28 12:06:02\n",
      "epoch: 4/100 | trn loss: 0.9014 | val loss: 0.8667 | val accuracy: 70.1090% \n",
      "\n",
      "2020/09/28 12:06:15\n",
      "epoch: 5/100 | trn loss: 0.8575 | val loss: 0.8500 | val accuracy: 70.3532% \n",
      "\n",
      "2020/09/28 12:06:28\n",
      "epoch: 6/100 | trn loss: 0.8195 | val loss: 0.8213 | val accuracy: 71.3867% \n",
      "\n",
      "2020/09/28 12:06:42\n",
      "epoch: 7/100 | trn loss: 0.7980 | val loss: 0.8154 | val accuracy: 71.0449% \n",
      "\n",
      "2020/09/28 12:06:55\n",
      "epoch: 8/100 | trn loss: 0.7822 | val loss: 0.7975 | val accuracy: 70.8333% \n",
      "\n",
      "2020/09/28 12:07:08\n",
      "epoch: 9/100 | trn loss: 0.7696 | val loss: 0.7395 | val accuracy: 72.2738% \n",
      "\n",
      "2020/09/28 12:07:21\n",
      "epoch: 10/100 | trn loss: 0.7406 | val loss: 0.7962 | val accuracy: 72.7783% \n",
      "\n",
      "2020/09/28 12:07:34\n",
      "epoch: 11/100 | trn loss: 0.7341 | val loss: 0.7801 | val accuracy: 73.3561% \n",
      "\n",
      "Model replaced and saved as  Otto_model_minloss_0.780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-kunwoopark/.local/lib/python3.7/site-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type Model. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/09/28 12:07:47\n",
      "epoch: 12/100 | trn loss: 0.7184 | val loss: 0.7913 | val accuracy: 72.4609% \n",
      "\n",
      "2020/09/28 12:08:00\n",
      "epoch: 13/100 | trn loss: 0.7056 | val loss: 0.7703 | val accuracy: 73.1038% \n",
      "\n",
      "Model replaced and saved as  Otto_model_minloss_0.770\n",
      "2020/09/28 12:08:13\n",
      "epoch: 14/100 | trn loss: 0.7024 | val loss: 0.7655 | val accuracy: 73.1445% \n",
      "\n",
      "Model replaced and saved as  Otto_model_minloss_0.766\n",
      "2020/09/28 12:08:26\n",
      "epoch: 15/100 | trn loss: 0.6831 | val loss: 0.7714 | val accuracy: 73.2829% \n",
      "\n",
      "2020/09/28 12:08:39\n",
      "epoch: 16/100 | trn loss: 0.6792 | val loss: 0.7694 | val accuracy: 74.0397% \n",
      "\n",
      "2020/09/28 12:08:52\n",
      "epoch: 17/100 | trn loss: 0.6699 | val loss: 0.7878 | val accuracy: 73.1852% \n",
      "\n",
      "2020/09/28 12:09:05\n",
      "epoch: 18/100 | trn loss: 0.6734 | val loss: 0.7682 | val accuracy: 73.7549% \n",
      "\n",
      "2020/09/28 12:09:18\n",
      "epoch: 19/100 | trn loss: 0.6602 | val loss: 0.7813 | val accuracy: 74.2188% \n",
      "\n",
      "2020/09/28 12:09:30\n",
      "epoch: 20/100 | trn loss: 0.6484 | val loss: 0.7539 | val accuracy: 74.3490% \n",
      "\n",
      "Model replaced and saved as  Otto_model_minloss_0.754\n",
      "2020/09/28 12:09:44\n",
      "epoch: 21/100 | trn loss: 0.6436 | val loss: 0.7817 | val accuracy: 72.7458% \n",
      "\n",
      "2020/09/28 12:09:57\n",
      "epoch: 22/100 | trn loss: 0.6420 | val loss: 0.7710 | val accuracy: 73.8200% \n",
      "\n",
      "2020/09/28 12:10:10\n",
      "epoch: 23/100 | trn loss: 0.6389 | val loss: 0.7668 | val accuracy: 74.5199% \n",
      "\n",
      "2020/09/28 12:10:23\n",
      "epoch: 24/100 | trn loss: 0.6372 | val loss: 0.7772 | val accuracy: 74.1292% \n",
      "\n",
      "2020/09/28 12:10:35\n",
      "epoch: 25/100 | trn loss: 0.6472 | val loss: 0.7711 | val accuracy: 74.0804% \n",
      "\n",
      "2020/09/28 12:10:48\n",
      "epoch: 26/100 | trn loss: 0.6269 | val loss: 0.7984 | val accuracy: 73.5921% \n",
      "\n",
      "2020/09/28 12:11:01\n",
      "epoch: 27/100 | trn loss: 0.6253 | val loss: 0.7714 | val accuracy: 74.6094% \n",
      "\n",
      "2020/09/28 12:11:14\n",
      "epoch: 28/100 | trn loss: 0.6206 | val loss: 0.7882 | val accuracy: 74.2269% \n",
      "\n",
      "2020/09/28 12:11:27\n",
      "epoch: 29/100 | trn loss: 0.6190 | val loss: 0.8093 | val accuracy: 73.8281% \n",
      "\n",
      "2020/09/28 12:11:40\n",
      "epoch: 30/100 | trn loss: 0.6078 | val loss: 0.7932 | val accuracy: 73.7386% \n",
      "\n",
      "2020/09/28 12:11:53\n",
      "epoch: 31/100 | trn loss: 0.6165 | val loss: 0.7917 | val accuracy: 73.9502% \n",
      "\n",
      "2020/09/28 12:12:06\n",
      "epoch: 32/100 | trn loss: 0.6089 | val loss: 0.8205 | val accuracy: 73.6654% \n",
      "\n",
      "2020/09/28 12:12:19\n",
      "epoch: 33/100 | trn loss: 0.5953 | val loss: 0.8071 | val accuracy: 73.5921% \n",
      "\n",
      "2020/09/28 12:12:32\n",
      "epoch: 34/100 | trn loss: 0.5993 | val loss: 0.7826 | val accuracy: 74.2757% \n",
      "\n",
      "2020/09/28 12:12:45\n",
      "epoch: 35/100 | trn loss: 0.5902 | val loss: 0.8217 | val accuracy: 73.7305% \n",
      "\n",
      "2020/09/28 12:12:58\n",
      "epoch: 36/100 | trn loss: 0.5942 | val loss: 0.7972 | val accuracy: 74.4548% \n",
      "\n",
      "2020/09/28 12:13:11\n",
      "epoch: 37/100 | trn loss: 0.5886 | val loss: 0.8156 | val accuracy: 74.4059% \n",
      "\n",
      "2020/09/28 12:13:24\n",
      "epoch: 38/100 | trn loss: 0.5847 | val loss: 0.8173 | val accuracy: 74.1211% \n",
      "\n",
      "2020/09/28 12:13:38\n",
      "epoch: 39/100 | trn loss: 0.5835 | val loss: 0.8066 | val accuracy: 73.2422% \n",
      "\n",
      "2020/09/28 12:13:50\n",
      "epoch: 40/100 | trn loss: 0.5758 | val loss: 0.7842 | val accuracy: 75.0488% \n",
      "\n",
      "2020/09/28 12:14:04\n",
      "epoch: 41/100 | trn loss: 0.5691 | val loss: 0.8199 | val accuracy: 74.2513% \n",
      "\n",
      "2020/09/28 12:14:17\n",
      "epoch: 42/100 | trn loss: 0.5663 | val loss: 0.8028 | val accuracy: 73.8200% \n",
      "\n",
      "2020/09/28 12:14:30\n",
      "epoch: 43/100 | trn loss: 0.5656 | val loss: 0.8220 | val accuracy: 73.5758% \n",
      "\n",
      "2020/09/28 12:14:43\n",
      "epoch: 44/100 | trn loss: 0.5532 | val loss: 0.8318 | val accuracy: 74.2920% \n",
      "\n",
      "2020/09/28 12:14:56\n",
      "epoch: 45/100 | trn loss: 0.5557 | val loss: 0.8238 | val accuracy: 74.1048% \n",
      "\n",
      "2020/09/28 12:15:09\n",
      "epoch: 46/100 | trn loss: 0.5503 | val loss: 0.8272 | val accuracy: 73.2829% \n",
      "\n",
      "2020/09/28 12:15:22\n",
      "epoch: 47/100 | trn loss: 0.5425 | val loss: 0.7948 | val accuracy: 74.7803% \n",
      "\n",
      "2020/09/28 12:15:35\n",
      "epoch: 48/100 | trn loss: 0.5356 | val loss: 0.8611 | val accuracy: 73.2503% \n",
      "\n",
      "2020/09/28 12:15:48\n",
      "epoch: 49/100 | trn loss: 0.5295 | val loss: 0.8229 | val accuracy: 74.4548% \n",
      "\n",
      "2020/09/28 12:16:02\n",
      "epoch: 50/100 | trn loss: 0.5410 | val loss: 0.8013 | val accuracy: 74.9023% \n",
      "\n",
      "2020/09/28 12:16:15\n",
      "epoch: 51/100 | trn loss: 0.5206 | val loss: 0.8092 | val accuracy: 74.7884% \n",
      "\n",
      "2020/09/28 12:16:28\n",
      "epoch: 52/100 | trn loss: 0.5211 | val loss: 0.8082 | val accuracy: 74.2594% \n",
      "\n",
      "2020/09/28 12:16:41\n",
      "epoch: 53/100 | trn loss: 0.5122 | val loss: 0.8207 | val accuracy: 73.8525% \n",
      "\n",
      "2020/09/28 12:16:54\n",
      "epoch: 54/100 | trn loss: 0.5058 | val loss: 0.8206 | val accuracy: 74.4792% \n",
      "\n",
      "2020/09/28 12:17:07\n",
      "epoch: 55/100 | trn loss: 0.5064 | val loss: 0.8562 | val accuracy: 73.3398% \n",
      "\n",
      "2020/09/28 12:17:21\n",
      "epoch: 56/100 | trn loss: 0.5174 | val loss: 0.8981 | val accuracy: 73.8525% \n",
      "\n",
      "2020/09/28 12:17:34\n",
      "epoch: 57/100 | trn loss: 0.5212 | val loss: 0.8637 | val accuracy: 74.9512% \n",
      "\n",
      "2020/09/28 12:17:47\n",
      "epoch: 58/100 | trn loss: 0.4978 | val loss: 0.8716 | val accuracy: 74.2757% \n",
      "\n",
      "2020/09/28 12:18:00\n",
      "epoch: 59/100 | trn loss: 0.4929 | val loss: 0.8555 | val accuracy: 73.5677% \n",
      "\n",
      "2020/09/28 12:18:13\n",
      "epoch: 60/100 | trn loss: 0.4878 | val loss: 0.8560 | val accuracy: 73.0794% \n",
      "\n",
      "2020/09/28 12:18:26\n",
      "epoch: 61/100 | trn loss: 0.4917 | val loss: 0.8383 | val accuracy: 73.4945% \n",
      "\n",
      "2020/09/28 12:18:39\n",
      "epoch: 62/100 | trn loss: 0.4813 | val loss: 0.8913 | val accuracy: 74.6989% \n",
      "\n",
      "2020/09/28 12:18:53\n",
      "epoch: 63/100 | trn loss: 0.4819 | val loss: 0.8963 | val accuracy: 74.3571% \n",
      "\n",
      "2020/09/28 12:19:06\n",
      "epoch: 64/100 | trn loss: 0.4791 | val loss: 0.9229 | val accuracy: 74.2757% \n",
      "\n",
      "2020/09/28 12:19:19\n",
      "epoch: 65/100 | trn loss: 0.4749 | val loss: 0.8841 | val accuracy: 72.9899% \n",
      "\n",
      "2020/09/28 12:19:32\n",
      "epoch: 66/100 | trn loss: 0.4681 | val loss: 0.9051 | val accuracy: 74.3734% \n",
      "\n",
      "2020/09/28 12:19:45\n",
      "epoch: 67/100 | trn loss: 0.4655 | val loss: 0.8747 | val accuracy: 74.6094% \n",
      "\n",
      "2020/09/28 12:19:58\n",
      "epoch: 68/100 | trn loss: 0.4663 | val loss: 0.8934 | val accuracy: 73.7305% \n",
      "\n",
      "2020/09/28 12:20:11\n",
      "epoch: 69/100 | trn loss: 0.4769 | val loss: 0.9291 | val accuracy: 73.9502% \n",
      "\n",
      "2020/09/28 12:20:25\n",
      "epoch: 70/100 | trn loss: 0.4679 | val loss: 0.8517 | val accuracy: 75.0081% \n",
      "\n",
      "2020/09/28 12:20:38\n",
      "epoch: 71/100 | trn loss: 0.4580 | val loss: 0.9477 | val accuracy: 73.6572% \n",
      "\n",
      "2020/09/28 12:20:51\n",
      "epoch: 72/100 | trn loss: 0.4534 | val loss: 0.9661 | val accuracy: 74.7314% \n",
      "\n",
      "2020/09/28 12:21:04\n",
      "epoch: 73/100 | trn loss: 0.4562 | val loss: 0.8987 | val accuracy: 75.0488% \n",
      "\n",
      "2020/09/28 12:21:17\n",
      "epoch: 74/100 | trn loss: 0.4578 | val loss: 0.9370 | val accuracy: 73.6491% \n",
      "\n",
      "2020/09/28 12:21:30\n",
      "epoch: 75/100 | trn loss: 0.4539 | val loss: 0.9654 | val accuracy: 74.4303% \n",
      "\n",
      "2020/09/28 12:21:44\n",
      "epoch: 76/100 | trn loss: 0.4489 | val loss: 0.9193 | val accuracy: 74.2432% \n",
      "\n",
      "2020/09/28 12:21:56\n",
      "epoch: 77/100 | trn loss: 0.4413 | val loss: 0.9421 | val accuracy: 74.2188% \n",
      "\n",
      "2020/09/28 12:22:09\n",
      "epoch: 78/100 | trn loss: 0.4406 | val loss: 0.8903 | val accuracy: 74.3815% \n",
      "\n",
      "2020/09/28 12:22:21\n",
      "epoch: 79/100 | trn loss: 0.4377 | val loss: 0.8808 | val accuracy: 74.8291% \n",
      "\n",
      "2020/09/28 12:22:34\n",
      "epoch: 80/100 | trn loss: 0.4384 | val loss: 0.9869 | val accuracy: 73.7874% \n",
      "\n",
      "2020/09/28 12:22:48\n",
      "epoch: 81/100 | trn loss: 145984.1274 | val loss: 29964.2422 | val accuracy: 16.6341% \n",
      "\n",
      "2020/09/28 12:23:01\n",
      "epoch: 82/100 | trn loss: 1276.1618 | val loss: 102.8568 | val accuracy: 27.2217% \n",
      "\n",
      "2020/09/28 12:23:14\n",
      "epoch: 83/100 | trn loss: 69.7856 | val loss: 60.7619 | val accuracy: 50.5371% \n",
      "\n",
      "2020/09/28 12:23:27\n",
      "epoch: 84/100 | trn loss: 38.7413 | val loss: 31.5890 | val accuracy: 46.7285% \n",
      "\n",
      "2020/09/28 12:23:40\n",
      "epoch: 85/100 | trn loss: 33.1392 | val loss: 20.2632 | val accuracy: 53.2878% \n",
      "\n",
      "2020/09/28 12:23:53\n",
      "epoch: 86/100 | trn loss: 28.6748 | val loss: 21.2516 | val accuracy: 37.9639% \n",
      "\n",
      "2020/09/28 12:24:06\n",
      "epoch: 87/100 | trn loss: 28.4591 | val loss: 50.6522 | val accuracy: 32.7474% \n",
      "\n",
      "2020/09/28 12:24:20\n",
      "epoch: 88/100 | trn loss: 23.6692 | val loss: 21.8691 | val accuracy: 37.9720% \n",
      "\n",
      "2020/09/28 12:24:33\n",
      "epoch: 89/100 | trn loss: 18.3874 | val loss: 13.0541 | val accuracy: 58.3333% \n",
      "\n",
      "2020/09/28 12:24:46\n",
      "epoch: 90/100 | trn loss: 15.3456 | val loss: 13.4791 | val accuracy: 46.6227% \n",
      "\n",
      "2020/09/28 12:24:59\n",
      "epoch: 91/100 | trn loss: 14.2273 | val loss: 19.0007 | val accuracy: 41.3086% \n",
      "\n",
      "2020/09/28 12:25:13\n",
      "epoch: 92/100 | trn loss: 14.3676 | val loss: 19.5343 | val accuracy: 58.0648% \n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/09/28 12:25:25\n",
      "epoch: 93/100 | trn loss: 13.3061 | val loss: 14.7904 | val accuracy: 35.3027% \n",
      "\n",
      "2020/09/28 12:25:38\n",
      "epoch: 94/100 | trn loss: 12.1539 | val loss: 7.3465 | val accuracy: 53.9714% \n",
      "\n",
      "2020/09/28 12:25:51\n",
      "epoch: 95/100 | trn loss: 10.5777 | val loss: 7.7308 | val accuracy: 45.5973% \n",
      "\n",
      "2020/09/28 12:26:04\n",
      "epoch: 96/100 | trn loss: 8.9386 | val loss: 8.3800 | val accuracy: 42.8955% \n",
      "\n",
      "2020/09/28 12:26:17\n",
      "epoch: 97/100 | trn loss: 9.6195 | val loss: 7.0349 | val accuracy: 44.9707% \n",
      "\n",
      "2020/09/28 12:26:30\n",
      "epoch: 98/100 | trn loss: 7.7411 | val loss: 7.7491 | val accuracy: 50.5697% \n",
      "\n",
      "2020/09/28 12:26:43\n",
      "epoch: 99/100 | trn loss: 7.3574 | val loss: 7.2358 | val accuracy: 56.7546% \n",
      "\n",
      "2020/09/28 12:26:56\n",
      "epoch: 100/100 | trn loss: 6.3696 | val loss: 3.9917 | val accuracy: 56.4941% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "trn_loss_list = []\n",
    "val_loss_list = []\n",
    "total_epoch=100\n",
    "model_char=\"minloss\"\n",
    "model_name=\"\"\n",
    "patience=5\n",
    "start_early_stop_check=0\n",
    "saving_start_epoch=10\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    trn_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data\n",
    "        if torch.cuda.is_available():\n",
    "            inputs=inputs.cuda()\n",
    "            labels=labels.cuda()\n",
    "        # grad init\n",
    "        optimizer.zero_grad()\n",
    "        # forward propagation\n",
    "        output= model(inputs)\n",
    "        # calculate loss\n",
    "        loss=criterion(output, labels)\n",
    "        # back propagation \n",
    "        loss.backward()\n",
    "        # weight update\n",
    "        optimizer.step()\n",
    "        \n",
    "        # trn_loss summary\n",
    "        trn_loss += loss.item()\n",
    "        # del (memory issue)\n",
    "        del loss\n",
    "        del output\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0.0\n",
    "        cor_match = 0\n",
    "        for j, val in enumerate(val_loader):\n",
    "            val_x, val_label = val\n",
    "            if torch.cuda.is_available():\n",
    "                val_x = val_x.cuda()\n",
    "                val_label =val_label.cuda()\n",
    "            val_output = model(val_x)\n",
    "            v_loss = criterion(val_output, val_label)\n",
    "            val_loss += v_loss\n",
    "            _, predicted=torch.max(val_output,1)\n",
    "            cor_match+=np.count_nonzero(predicted.cpu().detach()==val_label.cpu().detach())\n",
    "    del val_output\n",
    "    del v_loss\n",
    "    del predicted\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn_loss_list.append(trn_loss/len(train_loader))\n",
    "    val_loss_list.append(val_loss/len(val_loader))\n",
    "    val_acc=cor_match/(len(val_loader)*batch_size)\n",
    "    now = time.localtime()\n",
    "    print (\"%04d/%02d/%02d %02d:%02d:%02d\" % (now.tm_year, now.tm_mon, now.tm_mday, now.tm_hour, now.tm_min, now.tm_sec))\n",
    "\n",
    "    print(\"epoch: {}/{} | trn loss: {:.4f} | val loss: {:.4f} | val accuracy: {:.4f}% \\n\".format(\n",
    "                epoch+1, total_epoch, trn_loss / len(train_loader), val_loss / len(val_loader), val_acc*100\n",
    "            ))\n",
    "    \n",
    "    \n",
    "    if epoch+1>2:\n",
    "        if val_loss_list[-1]>val_loss_list[-2]:\n",
    "            start_early_stop_check=1\n",
    "    else:\n",
    "        val_loss_min=val_loss_list[-1]\n",
    "        \n",
    "    if start_early_stop_check:\n",
    "        early_stop_temp=val_loss_list[-patience:]\n",
    "        if all(early_stop_temp[i]<early_stop_temp[i+1] for i in range (len(early_stop_temp)-1)):\n",
    "            print(\"Early stop!\")\n",
    "            break\n",
    "            \n",
    "    if epoch+1>saving_start_epoch:\n",
    "        if val_loss_list[-1]<val_loss_min:\n",
    "            if os.path.isfile(model_name):\n",
    "                os.remove(model_name)\n",
    "            val_loss_min=val_loss_list[-1]\n",
    "            model_name=\"Otto_model_\"+model_char+\"_{:.3f}\".format(val_loss_min)\n",
    "            torch.save(model, model_name)\n",
    "            print(\"Model replaced and saved as \",model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
